{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import conv_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_size = 256\n",
    "latent_size = 512\n",
    "batch_size = 16\n",
    "cha = 24 #Should be 32\n",
    "n_layers = int(np.log2(im_size) - 2) # 5 for 128 \n",
    "mixed_prob = 0.9\n",
    "channels_mult_list = [1,2,4,6,8,16,32,32,64,64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_z(n):\n",
    "    # Z \n",
    "    return np.random.normal(0.0, 1.0, size = [n, latent_size]).astype('float32')\n",
    "\n",
    "def latent_z_list(n):\n",
    "    return [latent_z(n)] * n_layers\n",
    "\n",
    "def mixed_latent_z(n):\n",
    "    tt = int(np.random.random() * n_layers)\n",
    "    p1 = [latent_z(n)] * tt\n",
    "    p2 = [latent_z(n)] * (n_layers - tt)\n",
    "    return p1 + p2 #list concatenation\n",
    "\n",
    "def noise_image(batch_size):\n",
    "    return np.random.uniform(0.0, 1.0, size = [batch_size, im_size, im_size, 1]).astype('float32')\n",
    "\n",
    "#Loss functions\n",
    "def gradient_penalty(samples, output, weight):\n",
    "    gradients = K.gradients(output, samples)[0]\n",
    "    gradients_sqr = K.square(gradients)\n",
    "    gradient_penalty = K.sum(gradients_sqr,\n",
    "                              axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "\n",
    "    # (weight / 2) * ||grad||^2\n",
    "    # Penalize the gradient norm\n",
    "    return K.mean(gradient_penalty) * weight\n",
    "\n",
    "def crop_to_fit(x):\n",
    "    height = x[1].shape[1]\n",
    "    width = x[1].shape[2]\n",
    "    return x[0][:, :height, :width, :]\n",
    "\n",
    "def upsample(x):\n",
    "    return K.resize_images(x,2,2,\"channels_last\",interpolation='bilinear')\n",
    "\n",
    "def upsample_to_size(x):\n",
    "    y = im_size // x.shape[2]\n",
    "    x = K.resize_images(x, y, y, \"channels_last\",interpolation='bilinear')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_block(x, input_style, input_noise, nb_filters, upsampling = True):\n",
    "    input_filters = x.shape[-1]\n",
    "    if upsampling:\n",
    "        x = keras.layers.UpSampling2D(interpolation='bilinear')(x)\n",
    "        \n",
    "    \n",
    "    rgb_style = keras.layers.Dense(nb_filters, kernel_initializer = keras.initializers.VarianceScaling(200/x.shape[2]))(input_style)\n",
    "    style = keras.layers.Dense(input_filters, kernel_initializer = 'he_uniform')(input_style)\n",
    "    \n",
    "    noise_cropped = keras.layers.Lambda(crop_to_fit)([input_noise, x]) ########\n",
    "    d = keras.layers.Dense(nb_filters, kernel_initializer='zeros')(noise_cropped)\n",
    "\n",
    "    x = conv_mod.Conv2DMod(filters=nb_filters, kernel_size = 3, padding = 'same', kernel_initializer = 'he_uniform')([x, style])\n",
    "    x = keras.layers.add([x, d])\n",
    "    x = keras.layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    style = keras.layers.Dense(nb_filters, kernel_initializer = 'he_uniform')(input_style)\n",
    "    d = keras.layers.Dense(nb_filters, kernel_initializer = 'zeros')(noise_cropped)\n",
    "\n",
    "    x = conv_mod.Conv2DMod(filters = nb_filters, kernel_size = 3, padding = 'same', kernel_initializer = 'he_uniform')([x, style])\n",
    "    x = keras.layers.add([x, d])\n",
    "    x = keras.layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    return x, to_rgb(x, rgb_style)\n",
    "\n",
    "def d_block(inp, fil, p = True):\n",
    "\n",
    "    res = keras.layers.Conv2D(fil, 1, kernel_initializer = 'he_uniform')(inp)\n",
    "\n",
    "    out = keras.layers.Conv2D(filters = fil, kernel_size = 3, padding = 'same', kernel_initializer = 'he_uniform')(inp)\n",
    "    out = keras.layers.LeakyReLU(0.2)(out)\n",
    "    out = keras.layers.Conv2D(filters = fil, kernel_size = 3, padding = 'same', kernel_initializer = 'he_uniform')(out)\n",
    "    out = keras.layers.LeakyReLU(0.2)(out)\n",
    "\n",
    "    out = keras.layers.add([res, out])\n",
    "\n",
    "    if p:\n",
    "        out = keras.layers.AveragePooling2D()(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "def to_rgb(inp, style):\n",
    "    size = inp.shape[2]\n",
    "    x = conv_mod.Conv2DMod(3, 1, kernel_initializer = keras.initializers.VarianceScaling(200/size), \n",
    "                              demod = False)([inp, style])\n",
    "    return keras.layers.Lambda(upsample_to_size, output_shape=[None, im_size, im_size, None])(x)\n",
    "\n",
    "def from_rgb(inp, conc = None):\n",
    "    fil = int(im_size * 4 / inp.shape[2])\n",
    "    z = keras.layers.AveragePooling2D()(inp)\n",
    "    x = keras.layers.Conv2D(fil, 1, kernel_initializer = 'he_uniform')(z)\n",
    "    if conc is not None:\n",
    "        x = keras.layers.concatenate([x, conc])\n",
    "    return x, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleGan(keras.Model):\n",
    "    def __init__(self, steps = 0, lr = 0.0001, decay = 0.00001, log_steps=None):\n",
    "        super(StyleGan, self).__init__()\n",
    "        \n",
    "        #Models\n",
    "        self.D = self.make_discriminator()\n",
    "        self.S = self.make_style_map()\n",
    "        self.G = self.make_generator()\n",
    "        \n",
    "        #Config\n",
    "        self.LR = lr\n",
    "        self.steps = steps\n",
    "        self.beta = 0.999\n",
    "\n",
    "        self.G_opt = keras.optimizers.Adam(lr = self.LR, beta_1 = 0, beta_2 = 0.999)\n",
    "        self.D_opt = keras.optimizers.Adam(lr = self.LR, beta_1 = 0, beta_2 = 0.999)\n",
    "        \n",
    "        self.pl_mean = tf.Variable(0, dtype=tf.float32)\n",
    "        self.av = np.zeros([44])\n",
    "        \n",
    "        logdir = \"logs/train_data/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.log_steps = log_steps\n",
    "        if log_steps is not None:\n",
    "            self.file_writer = tf.summary.create_file_writer(logdir)\n",
    "        \n",
    "    def make_discriminator(self):\n",
    "        d_input = keras.layers.Input(shape = [im_size, im_size, 3])\n",
    "        x = d_input\n",
    "        \n",
    "        nb_d_layers = int(np.log2(im_size))\n",
    "        \n",
    "        channels_mult = 1\n",
    "        nb_D_layer = int(np.log2(im_size))\n",
    "        for channels_mult in channels_mult_list[:nb_D_layer-1]:\n",
    "            x = d_block(x, channels_mult * cha)\n",
    "            channels_mult*=2\n",
    "        x = d_block(x, channels_mult_list[nb_D_layer-1] * cha, p = False)\n",
    "        \n",
    "        x = keras.layers.Flatten()(x)\n",
    "        x = keras.layers.Dense(1, kernel_initializer = 'he_uniform')(x)\n",
    "        return keras.models.Model(inputs = d_input, outputs = x)\n",
    "\n",
    "    def make_style_map(self):\n",
    "        S = keras.models.Sequential()\n",
    "        S.add(keras.layers.Dense(512, input_shape = [latent_size]))\n",
    "        S.add(keras.layers.LeakyReLU(0.2))\n",
    "        S.add(keras.layers.Dense(512))\n",
    "        S.add(keras.layers.LeakyReLU(0.2))\n",
    "        S.add(keras.layers.Dense(512))\n",
    "        S.add(keras.layers.LeakyReLU(0.2))\n",
    "        S.add(keras.layers.Dense(512))\n",
    "        S.add(keras.layers.LeakyReLU(0.2))\n",
    "        return S\n",
    "    \n",
    "    def make_generator(self):\n",
    "        inp_style = keras.layers.Input([n_layers, 512])\n",
    "        inp_noise = keras.layers.Input([im_size, im_size, 1])\n",
    "    \n",
    "        #Latent\n",
    "        x = inp_style[:,0,:1] * 0 + 1\n",
    "\n",
    "        outs = []\n",
    "\n",
    "        start_dim = im_size // (2**n_layers)\n",
    "        x = keras.layers.Dense(4*4*4*cha, activation = 'relu', use_bias=False, \n",
    "                              kernel_initializer = 'random_normal')(x)\n",
    "        x = keras.layers.Reshape([start_dim, start_dim, start_dim*cha])(x)\n",
    "\n",
    "        \n",
    "        for i, channels_mult in enumerate(channels_mult_list[:n_layers][::-1]):\n",
    "            x, r = g_block(x, inp_style[:,i], inp_noise, channels_mult * cha, upsampling = (i!=0))  \n",
    "            outs.append(r)\n",
    "\n",
    "        x = keras.layers.add(outs)\n",
    "        x = keras.layers.Lambda(lambda y: y/2 + 0.5)(x) #Use values centered around 0, but normalize to [0, 1], providing better initialization\n",
    "\n",
    "        return keras.models.Model(inputs = [inp_style, inp_noise], outputs = x)\n",
    "\n",
    "    @tf.function\n",
    "    def tf_train_step(self, images, style1, style2, style2_idx, noise, perform_gp=True, perform_pl=False):\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            #Get style information\n",
    "            w_1 = self.S(style1)\n",
    "            w_2 = self.S(style2)\n",
    "            w_space = tf.repeat(tf.stack([w_1,w_2], axis=1),[style2_idx, n_layers-style2_idx],axis=1)\n",
    "            pl_lengths = self.pl_mean\n",
    "\n",
    "            #Generate images\n",
    "            generated_images = self.G([w_space,noise], training=True)\n",
    "\n",
    "            #Discriminate\n",
    "            real_output = self.D(images, training=True)\n",
    "            fake_output = self.D(generated_images, training=True)\n",
    "\n",
    "            #Hinge loss function\n",
    "            gen_loss = K.mean(fake_output)\n",
    "            divergence = K.mean(K.relu(1 + real_output) + K.relu(1 - fake_output))\n",
    "            disc_loss = divergence\n",
    "\n",
    "            if perform_gp:\n",
    "                #R1 gradient penalty\n",
    "                disc_loss += gradient_penalty(images, real_output, 10)\n",
    "\n",
    "            if perform_pl:\n",
    "                #Slightly adjust W space\n",
    "                w_space_2 = []\n",
    "                for i in range(n_layers):\n",
    "                    w_slice = w_space[:,i]\n",
    "                    std = 0.1 / (K.std(w_slice, axis = 0, keepdims = True) + 1e-8)\n",
    "                    w_space_2.append(w_slice + K.random_normal(tf.shape(w_slice)) / (std + 1e-8))\n",
    "                w_space_2 = tf.stack(w_space_2, axis=1)\n",
    "                #Generate from slightly adjusted W space\n",
    "                pl_images = self.G([w_space_2,noise], training=True)\n",
    "\n",
    "                #Get distance after adjustment (path length)\n",
    "                delta_g = K.mean(K.square(pl_images - generated_images), axis = [1, 2, 3])\n",
    "                pl_lengths = delta_g\n",
    "\n",
    "                gen_loss += K.mean(K.square(pl_lengths - self.pl_mean))*tf.cast(self.pl_mean==0, dtype=tf.float32)\n",
    "\n",
    "        #Get gradients for respective areas\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, self.G.trainable_variables + self.S.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.D.trainable_variables)\n",
    "\n",
    "        #Apply gradients\n",
    "        self.G_opt.apply_gradients(zip(gradients_of_generator, self.G.trainable_variables + self.S.trainable_variables))\n",
    "        self.D_opt.apply_gradients(zip(gradients_of_discriminator, self.D.trainable_variables))\n",
    "\n",
    "        return disc_loss, gen_loss, divergence, pl_lengths\n",
    "    \n",
    "    def train_step(self, args):\n",
    "        images, style1, style2, style2_idx, noise = args\n",
    "        self.steps += 1\n",
    "        \n",
    "        apply_gradient_penalty = self.steps % 2 == 0 or self.steps < 10000\n",
    "        apply_path_penalty = self.steps % 16 == 0\n",
    "        \n",
    "        disc_loss, gen_loss, divergence, pl_lengths = self.tf_train_step(images, style1, style2, \n",
    "                                                                         style2_idx, noise, \n",
    "                                                                         apply_gradient_penalty, \n",
    "                                                                         apply_path_penalty)\n",
    "        \n",
    "        self.pl_mean.assign(0.99*self.pl_mean + 0.01*tf.reduce_mean(pl_lengths))\n",
    "        \n",
    "        if self.log_steps and not self.steps % self.log_steps:\n",
    "            with self.file_writer.as_default():\n",
    "                noise = noise_image(9)\n",
    "                l_z = latent_z(9)\n",
    "                l_w = model.S(l_z)\n",
    "                style = tf.stack([l_w for i in range(n_layers)],axis=1)\n",
    "                generated = model.G([style,noise])\n",
    "                img = tf.concat([tf.concat([generated[3*i+k] for k in range(3)], axis=1) for i in range(3)], axis=0)\n",
    "                tf.summary.image(\"Training data\", [img], step=self.steps)\n",
    "        \n",
    "        return {\n",
    "            \"disc_loss\":disc_loss,\n",
    "            \"gen_loss\":gen_loss,\n",
    "            \"divergence\":divergence,\n",
    "            \"pl_lengths\":pl_lengths,\n",
    "        }\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(im_path):\n",
    "    im_file = tf.io.read_file(im_path)\n",
    "    im = tf.io.decode_jpeg(im_file, channels=3)\n",
    "    im = tf.image.resize(im, (im_size,im_size))\n",
    "    im = tf.image.random_flip_left_right(im)\n",
    "    im = tf.image.convert_image_dtype(im, tf.float32)/255\n",
    "    return im\n",
    "\n",
    "def train_dataset():\n",
    "    path = \"/Data/leo/dogs-face-2015/*.jpg\"\n",
    "    im_dataset = tf.data.Dataset.list_files(path)\n",
    "    im_dataset = im_dataset.map(read_image)\n",
    "    im_dataset = im_dataset.repeat()\n",
    "    im_dataset = im_dataset.batch(batch_size)\n",
    "    \n",
    "    nb_train_image = len(glob.glob(path))\n",
    "    print(\"Number of train images found:\", nb_train_image)\n",
    "    \n",
    "    def gen_latent_z():\n",
    "        while 1:\n",
    "            yield latent_z(batch_size)\n",
    " \n",
    "    def gen_noise():\n",
    "        while 1:\n",
    "            yield noise_image(batch_size)\n",
    "            \n",
    "    def gen_mixed_idx():\n",
    "        while 1:\n",
    "            if np.random.random() < mixed_prob:\n",
    "                yield np.random.randint(n_layers)\n",
    "            else:\n",
    "                yield n_layers\n",
    "                       \n",
    "    latent_z1_dataset = tf.data.Dataset.from_generator(gen_latent_z, tf.float32, output_shapes=(batch_size, latent_size))\n",
    "    latent_z2_dataset = tf.data.Dataset.from_generator(gen_latent_z, tf.float32, output_shapes=(batch_size, latent_size))\n",
    "    noise_dataset = tf.data.Dataset.from_generator(gen_noise, (tf.float32))\n",
    "    mixed_idx_dataset = tf.data.Dataset.from_generator(gen_mixed_idx, (tf.int32))\n",
    "    \n",
    "    dataset = tf.data.Dataset.zip((im_dataset, latent_z1_dataset, latent_z2_dataset, \n",
    "                                   mixed_idx_dataset, noise_dataset))\n",
    "    dataset = dataset.prefetch(1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StyleGan(log_steps=20)\n",
    "model.compile(run_eagerly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eagerly False: 328 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images found: 52597\n",
      "     62/Unknown - 71s 1s/step - disc_loss: 28.2474 - gen_loss: 6.2737 - divergence: 24.0026 - pl_lengths: 0.0170"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    dataset = train_dataset().take(52597//batch_size)\n",
    "    model.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def call(self, l_z, noise):\n",
    "#         l_w = self.S(l_z)\n",
    "#         style = tf.stack([l_w for i in range(n_layers)],axis=1)\n",
    "#         generated = self.G([style,noise])\n",
    "#         return generated\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
