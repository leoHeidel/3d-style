{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"private/flowers.txt\") as f:\n",
    "    machine_names = f.readlines()\n",
    "    machine_names = [n.strip() for n in machine_names][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_conda(machine_name):\n",
    "    process = subprocess.Popen(['ssh', machine_name, 'conda'],\n",
    "                     stdout=subprocess.PIPE, \n",
    "                     stderr=subprocess.PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "    return stderr == b\"\"\n",
    "\n",
    "conda_installation = \"/usr/bin/rm -fr /Data/leoÂ &&\\\n",
    "cd /Data &&\\\n",
    "mkdir leo &&\\\n",
    "chmod 700 leo/ &&\\\n",
    "cd leo &&\\\n",
    "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh &&\\\n",
    "chmod +x Miniconda3-latest-Linux-x86_64.sh &&\\\n",
    "./Miniconda3-latest-Linux-x86_64.sh -b -p /Data/leo/miniconda3 &&\\\n",
    "source ~/.bashrc &&\\\n",
    "conda create --name tf2 -y matplotlib pillow tqdm scikit-learn pandas jupyter tensorflow-gpu &&\\\n",
    "conda activate tf2 &&\\\n",
    "pip install tensorflow-gpu==2.3\"\n",
    "\n",
    "\n",
    "def install_conda(machine_name):\n",
    "    print(f\"installing conda on {machine_name}\")\n",
    "    process = subprocess.Popen(['ssh', machine_name, conda_installation],\n",
    "                     stdout=subprocess.PIPE, \n",
    "                     stderr=subprocess.PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "    #print(stdout)\n",
    "    assert has_conda(machine_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_data(machine_name):\n",
    "    process = subprocess.Popen(['ssh', machine_name, \"ls /Data/leo\"],\n",
    "                     stdout=subprocess.PIPE, \n",
    "                     stderr=subprocess.PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "    return b\"dogs-face-2015\" in stdout\n",
    "\n",
    "def copy_data(machine_name):\n",
    "    print(f\"Copying data to {machine_name}\")\n",
    "    process = subprocess.Popen(['scp', \"/Data/dataset/dogs-face-2015.zip\", f\"{machine_name}:/Data/leo\"],\n",
    "                     stdout=subprocess.PIPE, \n",
    "                     stderr=subprocess.PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "    assert not len(stderr), stderr\n",
    "    process = subprocess.Popen(['ssh', machine_name, \"cd /Data/leo && unzip -q dogs-face-2015.zip\"],\n",
    "                     stdout=subprocess.PIPE, \n",
    "                     stderr=subprocess.PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "    assert not len(stderr), stderr\n",
    "    assert has_data(machine_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_git(machine_name):\n",
    "    process = subprocess.Popen(['ssh', machine_name, \"ls /Data/leo\"],\n",
    "                     stdout=subprocess.PIPE, \n",
    "                     stderr=subprocess.PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "    return b\"stylegan2-keras\" in stdout\n",
    "\n",
    "def setup_git(machine_name):\n",
    "    print(f\"Downloading git of project to {machine_name}\")\n",
    "    process = subprocess.Popen(['ssh', machine_name, \n",
    "                                \"cd /Data/leo && git clone https://github.com/leoHeidel/stylegan2-keras.git\"],\n",
    "                     stdout=subprocess.PIPE, \n",
    "                     stderr=subprocess.PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "    assert not len(stderr), stderr\n",
    "    assert has_git(machine_name)\n",
    "    \n",
    "    \n",
    "def update_git(machine_name):\n",
    "    print(f\"Updating git of project on {machine_name}\")\n",
    "    process = subprocess.Popen(['ssh', machine_name, \n",
    "                                \"cd /Data/leo/stylegan2-keras\",\n",
    "                                \"&& git fetch --all && git reset --hard origin/multi-worker\"],\n",
    "                     stdout=subprocess.PIPE, \n",
    "                     stderr=subprocess.PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "    assert not len(stderr), stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for machine_name in machine_names:\n",
    "    if not has_conda(machine_name):\n",
    "        install_conda(machine_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for machine_name in machine_names:\n",
    "    if not has_data(machine_name):\n",
    "        copy_data(machine_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for machine_name in machine_names:\n",
    "    if not has_git(machine_name):\n",
    "        setup_git(machine_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating git of project on aerides\n",
      "Updating git of project on barlia\n",
      "Updating git of project on calanthe\n",
      "Updating git of project on diuris\n"
     ]
    }
   ],
   "source": [
    "for machine_name in machine_names:\n",
    "    update_git(machine_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting multi-worker-training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile multi-worker-training.py\n",
    "import json\n",
    "import os\n",
    "import tqdm\n",
    "#print(os.environ['TF_CONFIG'])\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lib_stylegan\n",
    "\n",
    "def is_chief(task_type, task_id):\n",
    "    # If `task_type` is None, this may be operating as single worker, which works\n",
    "    # effectively as chief.\n",
    "    return task_type is None or task_type == 'chief' or (\n",
    "        task_type == 'worker' and task_id == 0)\n",
    "\n",
    "\n",
    "tf_config = json.loads(os.environ['TF_CONFIG'])\n",
    "num_workers = len(tf_config['cluster']['worker'])\n",
    "\n",
    "im_size = 128\n",
    "latent_size = 256 \n",
    "channels = 24 # Should be at least 32 for good results\n",
    "#Chosing the number of layer this way, means we start with 4x4\n",
    "nb_layer = int(np.log2(im_size) - 1) \n",
    "\n",
    "path=\"/Data/leo/dogs-face-2015/*jpg\"\n",
    "\n",
    "per_worker_batch_size = 16\n",
    "global_batch_size = per_worker_batch_size * num_workers\n",
    "\n",
    "\n",
    "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "task_type, task_id = (strategy.cluster_resolver.task_type,\n",
    "                      strategy.cluster_resolver.task_id)\n",
    "global_batch_size = per_worker_batch_size * num_workers\n",
    "\n",
    "with strategy.scope():\n",
    "    model = lib_stylegan.style_gan.StyleGan(im_size=im_size, \n",
    "                                            latent_size=latent_size, \n",
    "                                            channels=channels,\n",
    "                                            nb_layer=nb_layer,\n",
    "                                            global_batch_size=global_batch_size)\n",
    "    model.compile(run_eagerly=True)\n",
    "\n",
    "dataset = lib_stylegan.dataset.train_dataset(path, \n",
    "                                             n_layers=nb_layer, \n",
    "                                             im_size=im_size, \n",
    "                                             batch_size=per_worker_batch_size,\n",
    "                                             latent_size=latent_size\n",
    "                                            )\n",
    "for args in tqdm.tqdm(dataset.take(100), total=100):\n",
    "    per_replica_losses = strategy.run(model.train_step, args=(args,))\n",
    "for args in tqdm.tqdm(dataset.take(1), total=1):\n",
    "    per_replica_losses = strategy.run(model.train_step, args=(args,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "port_start = 60110\n",
    "tf_config = {\n",
    "    'cluster': {\n",
    "        'worker': [f'{machine_name}:{port_start + i}' for i,machine_name in enumerate(['ferrari'] + machine_names)]\n",
    "    },\n",
    "    'task': {'type': 'worker', 'index': 0} \n",
    "}\n",
    "os.environ['TF_CONFIG'] = json.dumps(tf_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_job(machine_name, idx):\n",
    "    process = subprocess.Popen(['scp', \"multi-worker-training.py\", \n",
    "                                f\"{machine_name}:/Data/leo/stylegan2-keras/multi-worker-training.py\"],\n",
    "         stdout=subprocess.PIPE, \n",
    "         stderr=subprocess.PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "    assert not len(stderr), stderr\n",
    "    tf_config['task']['index'] = idx\n",
    "    config_str = json.dumps(tf_config)\n",
    "    process = subprocess.Popen(['ssh', machine_name, \n",
    "                                'conda activate tf2',\n",
    "                                '&&',\n",
    "                                f\"export TF_CONFIG='{config_str}'\",\n",
    "                                '&&',\n",
    "                                \"cd /Data/leo/stylegan2-keras/\",\n",
    "                                '&&',\n",
    "                                'python multi-worker-training.py'\n",
    "                               ],\n",
    "         stdout=subprocess.PIPE, \n",
    "         stderr=subprocess.PIPE)\n",
    "    #stdout, stderr = process.communicate()\n",
    "    #print(stdout)\n",
    "    #print(stderr)\n",
    "    return process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on aerides\n",
      "Running on barlia\n",
      "Running on calanthe\n",
      "Running on diuris\n"
     ]
    }
   ],
   "source": [
    "processes = []\n",
    "for i,machine_name in enumerate(machine_names):\n",
    "    print(\"Running on\", machine_name)\n",
    "    processes.append(run_job(machine_name, i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"cluster\": {\"worker\": [\"ferrari:60100\", \"aerides:60101\", \"barlia:60102\", \"calanthe:60103\", \"diuris:60104\"]}, \"task\": {\"type\": \"worker\", \"index\": 1}}\\n'\n",
      "b'2020-12-06 22:01:42.511659: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\\n2020-12-06 22:01:43.293177: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\\n2020-12-06 22:01:43.297263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n2020-12-06 22:01:43.297625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \\npciBusID: 0000:01:00.0 name: Quadro P2000 computeCapability: 6.1\\ncoreClock: 1.4805GHz coreCount: 8 deviceMemorySize: 4.92GiB deviceMemoryBandwidth: 130.53GiB/s\\n2020-12-06 22:01:43.297655: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\\n2020-12-06 22:01:43.298912: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\\n2020-12-06 22:01:43.300240: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\\n2020-12-06 22:01:43.300511: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\\n2020-12-06 22:01:43.301871: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\\n2020-12-06 22:01:43.302575: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\\n2020-12-06 22:01:43.305304: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\\n2020-12-06 22:01:43.305430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n2020-12-06 22:01:43.306005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n2020-12-06 22:01:43.306358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\\n2020-12-06 22:01:43.306662: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\\n2020-12-06 22:01:43.312728: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3792000000 Hz\\n2020-12-06 22:01:43.314127: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5583917bab90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\\n2020-12-06 22:01:43.314140: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\\n2020-12-06 22:01:43.363403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n2020-12-06 22:01:43.363749: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5583917bd7a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\\n2020-12-06 22:01:43.363763: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P2000, Compute Capability 6.1\\n2020-12-06 22:01:43.363899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n2020-12-06 22:01:43.364082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \\npciBusID: 0000:01:00.0 name: Quadro P2000 computeCapability: 6.1\\ncoreClock: 1.4805GHz coreCount: 8 deviceMemorySize: 4.92GiB deviceMemoryBandwidth: 130.53GiB/s\\n2020-12-06 22:01:43.364099: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\\n2020-12-06 22:01:43.364111: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\\n2020-12-06 22:01:43.364120: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\\n2020-12-06 22:01:43.364128: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\\n2020-12-06 22:01:43.364136: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\\n2020-12-06 22:01:43.364143: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\\n2020-12-06 22:01:43.364151: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\\n2020-12-06 22:01:43.364189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n2020-12-06 22:01:43.364389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n2020-12-06 22:01:43.364560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\\n2020-12-06 22:01:43.364576: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\\n2020-12-06 22:01:43.638006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\\n2020-12-06 22:01:43.638031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \\n2020-12-06 22:01:43.638052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \\n2020-12-06 22:01:43.638239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n2020-12-06 22:01:43.638588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n2020-12-06 22:01:43.638855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 131 MB memory) -> physical GPU (device: 0, name: Quadro P2000, pci bus id: 0000:01:00.0, compute capability: 6.1)\\n2020-12-06 22:01:43.641276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n2020-12-06 22:01:43.641465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \\npciBusID: 0000:01:00.0 name: Quadro P2000 computeCapability: 6.1\\ncoreClock: 1.4805GHz coreCount: 8 deviceMemorySize: 4.92GiB deviceMemoryBandwidth: 130.53GiB/s\\n2020-12-06 22:01:43.641482: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\\n2020-12-06 22:01:43.641496: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\\n2020-12-06 22:01:43.641505: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\\n2020-12-06 22:01:43.641513: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\\n2020-12-06 22:01:43.641521: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\\n2020-12-06 22:01:43.641530: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\\n2020-12-06 22:01:43.641538: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\\n2020-12-06 22:01:43.641577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n2020-12-06 22:01:43.641778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n2020-12-06 22:01:43.641935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\\n2020-12-06 22:01:43.641950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\\n2020-12-06 22:01:43.641955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \\n2020-12-06 22:01:43.641958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \\n2020-12-06 22:01:43.642014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n2020-12-06 22:01:43.642227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\\n2020-12-06 22:01:43.642398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:worker/replica:0/task:1/device:GPU:0 with 131 MB memory) -> physical GPU (device: 0, name: Quadro P2000, pci bus id: 0000:01:00.0, compute capability: 6.1)\\nE1206 22:01:43.643241435   11977 server_chttp2.cc:40]        {\"created\":\"@1607288503.643210692\",\"description\":\"No address added out of total 1 resolved\",\"file\":\"external/com_github_grpc_grpc/src/core/ext/transport/chttp2/server/chttp2_server.cc\",\"file_line\":395,\"referenced_errors\":[{\"created\":\"@1607288503.643209121\",\"description\":\"Failed to add any wildcard listeners\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/iomgr/tcp_server_posix.cc\",\"file_line\":342,\"referenced_errors\":[{\"created\":\"@1607288503.643196812\",\"description\":\"Address family not supported by protocol\",\"errno\":97,\"file\":\"external/com_github_grpc_grpc/src/core/lib/iomgr/socket_utils_common_posix.cc\",\"file_line\":420,\"os_error\":\"Address family not supported by protocol\",\"syscall\":\"socket\",\"target_address\":\"[::]:60101\"},{\"created\":\"@1607288503.643208850\",\"description\":\"Unable to configure socket\",\"fd\":24,\"file\":\"external/com_github_grpc_grpc/src/core/lib/iomgr/tcp_server_utils_posix_common.cc\",\"file_line\":216,\"referenced_errors\":[{\"created\":\"@1607288503.643207424\",\"description\":\"Address already in use\",\"errno\":98,\"file\":\"external/com_github_grpc_grpc/src/core/lib/iomgr/tcp_server_utils_posix_common.cc\",\"file_line\":189,\"os_error\":\"Address already in use\",\"syscall\":\"bind\"}]}]}]}\\n2020-12-06 22:01:43.643265: E tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:525] Unknown: Could not start gRPC server\\n2020-12-06 22:01:43.643641: E tensorflow/c/c_api_experimental.cc:518] Could not start gRPC server\\nTraceback (most recent call last):\\n  File \"multi-worker-training.py\", line 35, in <module>\\n    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\\n  File \"/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py\", line 101, in __init__\\n    CollectiveAllReduceExtended(\\n  File \"/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py\", line 191, in __init__\\n    self._initialize_strategy(self._cluster_resolver)\\n  File \"/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py\", line 199, in _initialize_strategy\\n    self._initialize_multi_worker(cluster_resolver)\\n  File \"/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py\", line 326, in _initialize_multi_worker\\n    context.context().ensure_initialized()\\n  File \"/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/context.py\", line 551, in ensure_initialized\\n    pywrap_tfe.TFE_EnableCollectiveOps(context_handle, server_def_str)\\ntensorflow.python.framework.errors_impl.UnknownError: Could not start gRPC server\\n'\n"
     ]
    }
   ],
   "source": [
    "#stdout, stderr = processes[0].communicate()\n",
    "#print(stdout)\n",
    "#print(stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabled multi-worker collective ops with available devices: ['/job:worker/replica:0/task:0/device:CPU:0', '/job:worker/replica:0/task:0/device:XLA_CPU:0', '/job:worker/replica:0/task:0/device:XLA_GPU:0', '/job:worker/replica:0/task:0/device:GPU:0']\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['ferrari:60100', 'aerides:60101', 'barlia:60102', 'calanthe:60103', 'diuris:60104']}, task_type = 'worker', task_id = 0, num_workers = 5, local_devices = ('/job:worker/task:0/device:GPU:0',), communication = CollectiveCommunication.AUTO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images found: 52597\n",
      "INFO:tensorflow:Error reported to Coordinator: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n",
      "    yield\n",
      "  File \"/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_run.py\", line 199, in _call_for_each_replica\n",
      "    t.has_paused.wait()\n",
      "  File \"/Data/leo/miniconda3/envs/tf2/lib/python3.8/threading.py\", line 558, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/Data/leo/miniconda3/envs/tf2/lib/python3.8/threading.py\", line 302, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:57<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-f3c42ece351a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m                                             )\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mper_replica_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mper_replica_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1209\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1210\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1211\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m   \u001b[0;31m# TODO(b/151224785): Remove deprecated alias.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2583\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_strategy.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m     return mirrored_run.call_for_each_replica(\n\u001b[0m\u001b[1;32m    585\u001b[0m         self._container_strategy(), fn, args, kwargs)\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_run.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(strategy, fn, args, kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m                                             fn.python_function))\n\u001b[1;32m     77\u001b[0m       \u001b[0m_cfer_fn_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 696\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    697\u001b[0m             *args, **kwds))\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3065\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    960\u001b[0m           \u001b[0;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             return autograph.converted_call(\n\u001b[0m\u001b[1;32m    963\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    476\u001b[0m     logging.log(3, 'Forwarding call of partial %s with\\n%s\\n%s\\n', f, new_args,\n\u001b[1;32m    477\u001b[0m                 new_kwargs)\n\u001b[0;32m--> 478\u001b[0;31m     return converted_call(\n\u001b[0m\u001b[1;32m    479\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_run.py\u001b[0m in \u001b[0;36mtf__call_for_each_replica\u001b[0;34m(strategy, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m                         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wrapped'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdef_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'_cfer_fn_cache[strategy]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cfer_fn_cache[strategy][fn]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'do_return'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'retval_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_return\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf__call_for_each_replica\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36mif_stmt\u001b[0;34m(cond, body, orelse, get_state, set_state, symbol_names, nouts)\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0m_tf_if_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morelse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m     \u001b[0m_py_if_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morelse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36m_py_if_stmt\u001b[0;34m(cond, body, orelse)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_py_if_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morelse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m   \u001b[0;34m\"\"\"Overload of if_stmt that executes a Python if statement.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcond\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0morelse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_run.py\u001b[0m in \u001b[0;36melse_body_5\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                         \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m                     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                         \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_whitelisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_run.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(distribution, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m       \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdistribute_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_result\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/leo/miniconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/training/coordinator.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, threads, stop_grace_period_secs, ignore_live_threads)\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0mstop_wait_secs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstop_grace_period_secs\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_wait_secs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m       \u001b[0mstop_grace_period_secs\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mstop_wait_secs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m       \u001b[0mstop_wait_secs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstop_wait_secs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lib_stylegan\n",
    "\n",
    "def is_chief(task_type, task_id):\n",
    "    # If `task_type` is None, this may be operating as single worker, which works\n",
    "    # effectively as chief.\n",
    "    return task_type is None or task_type == 'chief' or (\n",
    "        task_type == 'worker' and task_id == 0)\n",
    "\n",
    "\n",
    "tf_config = json.loads(os.environ['TF_CONFIG'])\n",
    "num_workers = len(tf_config['cluster']['worker'])\n",
    "\n",
    "im_size = 128\n",
    "latent_size = 256 \n",
    "channels = 24 # Should be at least 32 for good results\n",
    "#Chosing the number of layer this way, means we start with 4x4\n",
    "nb_layer = int(np.log2(im_size) - 1) \n",
    "\n",
    "path=\"/Data/leo/dogs-face-2015/*jpg\"\n",
    "\n",
    "per_worker_batch_size = 16\n",
    "global_batch_size = per_worker_batch_size * num_workers\n",
    "\n",
    "\n",
    "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "task_type, task_id = (strategy.cluster_resolver.task_type,\n",
    "                      strategy.cluster_resolver.task_id)\n",
    "global_batch_size = per_worker_batch_size * num_workers\n",
    "\n",
    "with strategy.scope():\n",
    "    model = lib_stylegan.style_gan.StyleGan(im_size=im_size, \n",
    "                                            latent_size=latent_size, \n",
    "                                            channels=channels,\n",
    "                                            nb_layer=nb_layer,\n",
    "                                            global_batch_size=global_batch_size)\n",
    "    model.compile(run_eagerly=True)\n",
    "\n",
    "dataset = lib_stylegan.dataset.train_dataset(path, \n",
    "                                             n_layers=nb_layer, \n",
    "                                             im_size=im_size, \n",
    "                                             batch_size=per_worker_batch_size,\n",
    "                                             latent_size=latent_size\n",
    "                                            )\n",
    "for args in tqdm.tqdm(dataset.take(100), total=100):\n",
    "    per_replica_losses = strategy.run(model.train_step, args=(args,))\n",
    "for args in tqdm.tqdm(dataset.take(1), total=1):\n",
    "    per_replica_losses = strategy.run(model.train_step, args=(args,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
